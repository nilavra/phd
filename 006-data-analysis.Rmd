# Data Analysis

<!----------- fig:data-analysis-framework ----------->
```{r data-analysis-framework, fig.scap='(ref:scap-data-analysis-framework)', fig.cap = '(ref:cap-data-analysis-framework)',  echo=FALSE, out.width='100%', fig.align='center'}
nbShowFig("figs/data-analysis-framework")
```
<!-- each text reference needs to be their own single paragraph ! -->
(ref:cap-data-analysis-framework) Data analysis framework followed in this dissertation.

(ref:scap-data-analysis-framework) Data analysis framework.

<!---- fig:data-analysis-framework (leave a blank line before this) ------>

Questionnaire Data

1. Cleaning and Preprocessing
2. identifying user groups - latent profile analysis

Log Data

1. Log Data cleaning and pre-processing
2. URL categorization
3. Active Tab Identification
4. Higher levelSearch Behaviour Data Analysis framework - moves, tactics, strategies
5. Combining Latent Profiles with Search Behaviour Data

Trends Over Time
Difference Between Groups / Profiles
Entropy analysis of sequences



## URL Categorization

<!-- ALL IN CAPS BECAUSE I WAS DOING URL CATEGORIZATION -->

- peer-reviewed publications are `PUB`s
- others are `ARTICLE`s (e.g. Wikipedia)
- if no other info, then `WEB`
- fuzzy between `WEB` and `ARTICLE` (when classified manually)
- `ARTICLE` if there is a clear author
  - except `WIKIPEDIA`, due to common parlance
  - encyclopedias
- journal homepages are `WEB`
- list of chapters in a book are `L.PUB`.
  - e.g. in detail view of
- book chapter is `PUB`

In order to understand the relationship between users' information search behavior and the type of webpages they visit, we needed to categorize webpages into different types. To accomplish this, we developed a classification system based on URL patterns.

URL patterns were first extracted from the web browsing data collected in our study. These URL patterns contain information about the structure and content of each webpage visited by the users. Based on this information, we were able to classify each webpage into one of several different types, including search engine result pages, content pages, scientific peer-reviewed publications, Wikipedia articles, library websites, or other types of webpages.

To identify search engine result pages, we looked for URLs that contained terms such as "search," "query," or "result," along with specific strings associated with popular search engines such as Google or Bing. We also identified content pages by looking for URLs that contained specific strings such as "article," "blog," "news," or "opinion." Scientific peer-reviewed publications were identified based on URLs that contained specific strings associated with academic publishers or databases, while Wikipedia articles were identified by their URLs containing the string "wiki."

Library websites were identified by URLs that contained terms such as "library," "catalog," or "database," as well as specific strings associated with major library systems. Finally, we used a catch-all category to identify other types of webpages that did not fit into any of the other categories.

Overall, our URL-based classification system provided a useful way to categorize webpages based on their type, allowing us to gain insights into how users' search behavior varies across different types of webpages. By analyzing the patterns of webpage types visited by users during their information search process, we were able to identify which types of webpages were most commonly visited and how they related to users' search behavior. This information can be used to improve the design of information systems and search engines, as well as to inform the development of tailored interventions that support users' information search needs.


## Latent Profile Analysis


<!-- @ambrose2010howa said that students' motivation, metacognition, and self-regulation determines, directs, and sustains what they do to learn.
We were interested to study the effect of these traits on students' search behaviour.
So we collected self-perceived reports of all 3 of them.
However, these constructs are not single binary variables that provide nice groupings automatically.
Instead they are multidimensional data, and are only observable indicators at best of the real hidden (latent) characteristic of an individual. 
In order to employ these multiple constructs to cluster participants into groups, we turned to psychology literature and latent class and latent profile methods. -->



According to @ambrose2010howa, students' motivation, metacognition, and self-regulation are critical factors that determine, direct, and sustain what they do to learn.
<!-- their learning behaviors.  -->
Given our interest in understanding how these traits impact students' searching as learning behaviour, we collected self-perceived reports of all three constructs, via the IMI, MAI, and SRQ questionnaires (Section \@ref(sec-method-qsnr1)). 
However, it is important to note that these constructs are not single binary variables that can be used to easily group individuals. Rather, they are complex and multidimensional data that serve as observable indicators of a person's underlying latent characteristics.


<!-- and utilized latent class and latent profile methods. These statistical techniques allow us to identify and describe subgroups within a population based on shared patterns of responses across multiple variables. By using these methods to analyze the self-perceived reports of motivation, metacognition, and self-regulation, we hope to gain a deeper understanding of how these traits relate to students' search behavior. Ultimately, this information could inform the design of interventions that are tailored to specific subgroups of students with distinct profiles of motivation, metacognition, and self-regulation. -->

<!-- Latent Profile Analysis (LPA) is one of the many approaches clustered together under the umbrella term person-centred statistical approaches, that is being increasingly used in Organizational Psychology, and child development research. LPA provides a framework for describing population heterogeneity in terms of differences across individuals on a set of behaviors or characteristics, as opposed to describing the variability of a single variable. This distinction has been described as a person-centered approach, in contrast to more traditional variable-centered approaches such as multiple regression analysis. The underlying principle of person-centered approaches is that, rather than quantifying the role of particular variables in a study, a population is organized in terms of a finite number of mutually exclusive and exhaustive subgroups, each comprising similar individuals. In other words, each Latent Profile (LP) represents a subgroup of individuals characterized by a pattern of responses on a set of variables; LPA is used to identify and describe the optimal number of LPs to represent a population. -->

To cluster participants into meaningful groups based on these multiple constructs, we turned to the educational psychology literature.
**Latent Profile Analysis (LPA)** is an increasingly popular statistical approach falling under the umbrella of person-centred techniques used in organizational psychology and child development research. It provides a framework for characterizing population heterogeneity in terms of differences across individuals on a set of behaviours or characteristics, as opposed to describing the variability of a single variable. By identifying latent subgroups within a population, LPA enables researchers to gain a more nuanced understanding of the complexity of human behaviour.

The person-centred approach underlying LPA is a departure from traditional variable-centered approaches such as multiple regression analysis. Instead of quantifying the role of particular variables in a study, LPA organizes a population into a finite number of mutually exclusive and exhaustive profiles, each comprising individuals who are similar to one another. In this way, LPA identifies distinct profiles of individuals who exhibit similar patterns of behaviour across multiple variables.

The identification and description of these latent profiles is a crucial step in LPA. Each profile represents a subgroup of individuals who share similar patterns of responses on a set of variables, which can provide insights into the underlying mechanisms driving their behaviour. Furthermore, the identification of the optimal number of profiles to represent a population is a critical issue in LPA. This involves balancing the complexity of the model with its ability to capture meaningful variability in the data, and requires careful consideration of both statistical and substantive criteria.

LPA has several advantages over traditional variable-centered approaches. It allows for a more nuanced understanding of the complexity of human behaviour, particularly in cases where individuals exhibit multiple and diverse patterns of behaviour across different sets of variables. 

In the context of information search behaviour, LPA can help to identify distinct groups of individuals who engage in different search strategies or have different search motivations. This can be useful for understanding how people search for information online, what factors influence their search behaviour, and how search behaviour relates to other variables such as task performance, satisfaction, and learning outcomes.




## Search Behaviour Data Analysis Framework

After log data was cleaned 
From @white2016interactions, Table 2.1 (adapted from Bates, 1989):

- **Level 1: Move**
  - Atomic search event – for example, a query or click
  (*An identifiable thought or action that is part of information searching.*)
- **Level 2: Tactic**
  - Goal or task, including query or click chain
  (*One or several moves made to further a search*)
- **Level 3: Statagem**
  - Mission or session
  (*A larger, more complex set of thoughts and/or actions than the tactic; a stratagem consists of multiple tactics and/or moves, all of which are designed to exploit a particular search domain that is thought to contain the desired information*)
- **Level 4: Strategy**
  - Session or cross-session search task
  (*A plan, which may contain moves, tactics, and/or stratagems, for an entire information search.*)








<!-- ========================= OLD CONTENT ==================== -->




Note about pronouns:
all participants are referred to using gender-neutral they/them pronouns.

Merge `SES2a` and `SES2b` into `SES2ab`

<!--
Analysis steps:
- Check analysis ideas for more ideas
- get data for IMI, MAI, etc
-->


## Data Cleaning and Processing

see crescenzi thesis

Session: `task_id`, 30 minutes of inactivity
(Google Analytics: a session lasts until there's 30 minutes of inactivity)

Session duration is considered 30 minutes (!) (or maybe 1 hour?)
as per Google Analytics^[https://www.hotjar.com/google-analytics/glossary/session-duration] and (TODO: find reference)

Possibility to create a step by step diagram? (powerpoint)

## Active Tab Identification for Log Parsing




## User characteristics: Latent Profiles

Finally using `HI` and `LO` groups.


- feature sets for profiling (toggle on and off)
  - `IMI`
  - `MAI`
  - `SRQ`
  - `WMC` / memory span:
    - scaling by dividing by 10 (?) (that's the max Coglab would show)


What factors are specifically responsible for the transitions or the changes in the Latent profiles at different points in the semester?

<!-- 
  - PLO: perceived learning outcome (/100): 
  - PSO: perceived search outcome (/100)
  - others?

PLO and PSO can't be used as there are multiple of them in SES1 and SES3 
-->

Memory span values normalized by 10, because "*The maximum memory span measurable with this experiment is ten*" as per CogLab output

- ~~Use LIME / SHAP and counterfactual explanations to understand which components contribute to change in Profile Membership~~
- no no; a simple examination of what feature values changed between timepoints will be enough
- use 2 groups! 2 groups is always better. easier to explain; easier to write.








## Level 1: Moves - Query Reformulation

- Yung Sheng's Dissertation
- [@hassan2014struggling] Table 1

Measures:

- Number of terms per Query
- Query length (characters?)
- Number of (unique) queries per search
- Number of reformulated query types
- Abandoned Queries (Percentage of queries with no clicks)
- query similarity [@hassan2014struggling]
  - average similarity between all queries to the first query in every session
  - exact match, approx match, lemma match, semantic match




## Level 1: Moves - Dwell Time (DT) - combined with URL types

URL type categories

(`Q` is a web-page type; `QUERY` is a move) 

- `Q`
  - BOOK / PUB / WEB / WORD ~~reform type~~
- `L`
  - `WEB%`
  - `PUB%`
  - `ARTICLE%`
  - `BOOK%`
  - `VIDEO%`
  - `COURSE%`
- `I`
  - all subcategories in `L` 
  - `CITATION%`
  - `FILE%`
- `NOTETAKING`
- `LONGSAL`
- `?` (`UNCLASSIFIED`)

Separately (as in [@lam2007session])
- `SEARCH`
- `LIB`
- `OTHER`

Dwell Time categories:

- `SHORT`: 1 - 5 seconds
  - "*A time span of less than 5 seconds is a too short period for being able to read a summary and extract information*" [@he2016beyond].
- `MEDIUM`: 5 - 30 seconds
- `LONG`: > 30 seconds
  - from Handehawa's thesis, and related Shah references


Other Ideas

- do analysis of `LIB` and `LIBGUIDE` type URLs - library websites
- Dwell Time:
  - overall
  - per-task
  - per timepoint?
- sig diff in DT between
  - `SES1` and `SES3`
  - `SES2a` and `SES2d`?
- checkout: `sns.pairplot()` -- pairwise relationships in a dataset
  - https://seaborn.pydata.org/generated/seaborn.pairplot.html
- checkout seaborn's plotting capabilites!


## Level 1: Moves - Interactions

Events

- `QUERY`
  - reformulation types
- `TAB`: Parallel Browsing Events
  - `OPEN`
  - `SWITCH`
  - `CLOSE`
- `TASK`: from YASBIL events and `task_id`
  - `START`
  - `END`
- `IDLE`: user stays idle for >=1 minute [@taramigkou2018leveraging]
  - `SHORT`: 1 - 5mins
  - `MEDIUM`: 5 - 30 mins
  - `LONG`: >= 30 mins -- treat as new session

`IDLE` could be PDF reading, or hand note-taking, or truly idle.

<!-- - not to be confused with SES1, SES2, SES3 etc.
    - think of a better name?
    - treat IDLE.LONG as new session? -->


## Level 2: Implicit Features for Exploratory Search Process

From @hendahewa2016implicit and related papers.

- **Creativity** --> Information Novelty
  - **Unique Coverage:** Unique web pages visited
  - **Likelihood of Discovery:** Measurement of difficulty to find certain information
- **Exploration**
  - **Total Coverage:** Total number of content pages visited
  - **Distinct Queries:** Total number of different queries issued
  - **Query diversity:** Measurement of similarity between queries issued
- **Knowledge Discovery** --> Finding useful and relevant information
  - **Useful Coverage:** Number of pages where users spend a considerable amount of time
  - **Relevant Coverage:** Number of pages that users denote as relevant to the task

https://rucore.libraries.rutgers.edu/rutgers-lib/49207/

<!-- - low priority
- chirag sha's student; has intersting metrics like coverage, unique pages visited etc.
- https://rucore.libraries.rutgers.edu/rutgers-lib/49207/
- maybe future work? -->





## Level 2+: Search Tactics and Strategies

Pernilla Q et al's paper: Jiyin He, Pernilla Qvarfort, Martin Halvey, Gene Golovchinsky. Beyond actions: Exploring the discovery of tactics from user logs. In Information Processing & Management, vol. 52, issue 6, Nov. 2016, pp. 1200–1226.

- http://dx.doi.org/10.1016/j.ipm.2016.05.007
- https://www.pernillaq.com/exploratory-search
- [checkout the forward citations of this paper on automated log analyses](https://scholar.google.com/scholar?cites=16001618163231710088&as_sdt=5,44&sciodt=0,44&hl=en)
- like process mining!
- "*Since modern search systems may allow user interactions beyond the tactics defined in the literature the tactics may need to be extended*"


Behaviours from *Search Patterns* book

- quit
- narrow
- expand
- pearl growing / citation mining / snowballing
- pogo sticking
- thrashing




### Strategies from webpage L2 categories only

No sense of time. Only events
query is a move, Q is aweb-page type

Tactics (per task)

- TASK.{START / END}
- QUERY.{types of reformulations} 
- Q.{BOOK / PUB / WEB / WORD}
- L.{`PUB` / `WEB` / `X`}
- L.click (only hyperlink clicks (?))
- I.{`PUB` / `WEB` / `ARTICLE` / X}
- I.click
- OTHER.{`X`}
- TAB.{tab events}
- IDLE.{DT categories}
  - IDLE.LONG = change of episode (or session)

<!-- - SESSION.{session events} -->


### Strategies from webpage L1 categories and Dwell Time (DT)

<!-- 
`SES2a` and `SES2b` have to be combined
(no: we are calculating per user-task, and taking care of episodes through IDLE time) 
-->

Tactics (per task)

- TASK.{START / END}
- Q.{types of reformulations}
- L.{DT categories}
- L.click (only hyperlink clicks (?))
- I.{DT categories}
- I.click
- OTHER.{DT categories}
- TAB.{tab events}
- IDLE.{DT categories}
  - IDLE.LONG = change of episode (or session)


<!-- 
- L.HOVER (?) (hover = reading?)
- SESSION.{session events}
- -->


### Strategies from webpage L2 categories and Dwell Time (DT)

Tactics (per task)

- TASK.{START / END}
- Q.{types of reformulations}
- L.{`PUB` / `WEB` / `X`}.{DT categories}
- L.click (only hyperlink clicks (?))
- I.{`PUB` / `WEB` / `ARTICLE` / X}.{DT categories}
- I.click
- OTHER.{`X`}.{DT categories}
- TAB.{tab events}
- IDLE.{DT categories}
  - IDLE.LONG =  change of episode (or session)




### Strategies from @lam2007session

- As in [@lam2007session] Sec 6 (`S` to denote a Search event and `X` to denote a non-search engine event):
  - Short Navigation: S(Start) --> X (End), with the S event limits to the first session events and the X event to the last events.
  - Topic Exploration: S --> X --> X --> X --> X --> ...
  - Methodical Results Exploration: S --> X --> S --> X --> S ...
  - Query Refinement: S --> S --> S --> S ...
- In our coding:
  - Short Navigation: QUERY --> non-Query (NQ: L / I / ?)
  - Topic Exploration: QUERY --> NQ --> NQ --> NQ --> NQ --> ...
  - etc.


- Using `WebNavigation` events and tab switches
- can do sequential pattern mining as in [@ibanez2022comparison]
  - maximal sequential pattern
  - etc.
- Other search patters:
  - `SS`: Search-engine Searches
  - `TS`: Third-party Searches using third-party online sites as search engines
  - `TE`: True Explorations of search results

### Struggling vs. Exploring

Indicators predictive of struggling [@hassan2014struggling]:

- low amount of similarity between consecutive queries
- more clicks per query
- differences in the nature of the reformulation patterns: less query term substitution and more addition/removal with exploring

<!-- Hassan et al. (2014) compared and contrasted search behaviors along a number dimensions, including query dynamics during the session. They found that there are some features that may be predictive of struggling, such as a low amount of similarity between consecutive queries, more clicks per query, as well as differences in the nature of the reformulation patterns (i.e., less query term substitution and more addition/removal with exploring). Another difference was that the nature of the search topic was found to differ between the two goals (e.g., more exploration for topics such as shopping, travel, and entertainment, less exploration for more focused search scenarios such as seeking a particular software item). Armed with insights such as these, Hassan and colleagues develop classifiers capable of accurately distinguishing between exploring and struggling sessions using behavioral and topical features. -->

### Navigators vs. Explorers

From IWSS book
(later, low priority)


<!-- 
### Original Idea

for LongSAL, tactics / states:

- Q
  - subdivided by Q reform types?
- L
- I\_short (DT <= 10s) -- rethink these durs
- I\_med ( 10 < DT <= 30s)
- I\_long (> 30s) 
  - 30s from Handehawa's thesis, and related Shah references
- opening a new tab: parallel mission?
- closing ta tab
- staying Idle (?) -- user stays idle for 1 minute -- as in taramigkou 2018 ip&m paper
- beginning and end of sessions?
- clicks?
  - clicks on L pages
  - clicks on I pages

or maybe I.type of webpage visited?
or combine DT with I.PUB / I.X? -->



### Transition analysis of Search Tactics / Strategies

Transition analysis can be applied to:

- search tactics
- tabs: parallel browsing behaviour (think hard... do we need a constant number of tabs for this to work?)
- combined (opening tab and closing tabs are tactics / events in Markov process)

Analyze / compare entropies and transition matrices across different tasks and sessions?
- e.g. SES1 tasks --> SES2 --> SES3

Help with analyses:

- Chen and Cooper (2002) used a Chi-square test to compare the distribution of transitions in search tactic transition matrices.
- [@he2016beyond p. 1220 sec 6.1] for calculation formulas for entropy of transitions
- [@krejtz2014entropy] sec 4 for calculation formulas
- [@he2016beyond p. 1220 sec 6.2] for hypotheses


## Correlation analysis

Correlation between user profiles and search tactics [Table 9 @taramigkou2018leveraging]



<!-- 
https://www.google.com/search?q=nilavra&oq=nilavra&aqs=edge..69i57j0i512j69i60l3j69i61j69i65j69i60j69i65.4522j0j4&sourceid=chrome&ie=UTF-8 
-->

Refer to Test PnG in Figure \@ref(fig:ResP4650362619704565728).


<!----------- fig:ResP4650362619704565728 ----------->
```{r ResP4650362619704565728, fig.scap='(ref:scap-ResP4650362619704565728)', fig.cap = '(ref:cap-ResP4650362619704565728)',  echo=FALSE, out.width='100%', fig.align='center'}
nbShowFig("figs/ResP4650362619704565728")
```
<!-- each text reference needs to be their own single paragraph ! -->
(ref:cap-ResP4650362619704565728) Longcaption.

(ref:scap-ResP4650362619704565728) Shortcaption.

<!---- fig:ResP4650362619704565728 (leave a blank line before this) ------>

