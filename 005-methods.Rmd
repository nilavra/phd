# Methods: LongSAL - the Longitudinal Study

To investigate the research questions and hypotheses discussed in Chapter \@ref(ch-rq), we conducted the LongSAL study.
The following sections discuss the study design, apparatus and procedure.

## Study Design and Participants {#sec-method-exp-design}

LongSAL (Longitudinal Search as Learning study) is a remote, exploratory, longitudinal study that was conducted between January and June 2022 (Spring semester) at the School of Information, University of Texas at Austin (UT Austin).
The study was approved by The University of Texas at Austin Institutional Review Board (Submission ID: `STUDY00002136`, Date Approved: December 8, 2021).


Participants were recruited from the student pool enrolled in the required undergraduate core-course: *Ethical Foundations for Informatics* [@fleischmann2022i303].
18 participants originally signed up for the study; 10 participants fully completed all the phases of the study, and the remaining 8 dropped off at different points during the semester.
Students enrolled in the course had to submit a research paper of 2,000-2,500 words as the final project for the course.
There were has four checkpoints spread across the semester to submit the drafts in progress: (i) paper proposal, (ii) outline, (iii) rough draft, and (iv) final paper.
Writing the research paper required choosing an informatics ethical dilemma, and applying three ethical perspectives covered in the course to explore potential solutions to the selected dilemma.
This involved searching and navigating information online, finding at least 20 relevant external sources, combining ideas, and weaving a narration around the information found in the selected sources.


The study design was informed by running a pilot study during Summer
2021 semester, in partnership with two courses at UT Austin School of
Information: *Information in Cyberspace*, and *Academic Success in the
Digital University*. 

<!--
More details of the pilot study are presented in
Appendix \@ref(ch-pilot-study). 

The final project overview from the *Information in Cyberspace* course is presented in Figure [1.1](#fig-final-project-description){reference-type="ref" reference="fig-final-project-description"}.  
-->



## Apparatus

### YASBIL Browsing Logger

The YASBIL browsing logger [@bhattacharya2021yasbil] was utilised
for this study. YASBIL (Yet Another Search Behaviour and Interaction
Logger)^[https://github.com/LongSAL/yasbil] is a two-component logging solution for ethically recording a
user's browsing activity for Interactive IR user studies. It was
developed by the author in early Spring 2021, and was employed in the
pilot study for data collection and testing. YASBIL comprises a Firefox
browser extension and a WordPress plugin. The browser extension logs
browsing activity in the participants' machines. The WordPress plugin
collects the logged data into the researcher's data server. YASBIL
captures participant's behavioural data, such as webpage visits, time
spent on pages, identification of popular search engines and their
SERPs, 
<!-- identifying rank of result clicked on SERPs,  -->
tracking mouse
clicks and scrolls, and the order and sequences of these events. The
logging works on any webpage, without the need to own or have knowledge
about the HTML structure of the webpage. To protect the privacy of
participants, the logger software can be switched on or off by the participant.
Participants received regular reminders to turn YASBIL on only when they were searching for information related to the course.

<!-- and participants will be instructed (and encouraged) to switch on the logger only when they are performing search activities related to the experiment.  -->
YASBIL offers ethical data transparency and security
for participants, by enabling them to view and obtain copies of the
logged data, as well as securely upload the data to the researcher's
server over an HTTPS connection. Although developed using the
cross-browser WebExtension API ^[https://developer.mozilla.org/en-US/docs/Mozilla/Add-ons/WebExtensions/Build-a-cross-browser-extension], YASBIL
currently works in the Firefox Web Browser. So participants were
instructed to install Firefox and YASBIL on their machines when they
volunteered to participate in the study.




<!-- ### Qualtrics Survey Software -->

<!-- ### Zoom Video-conferencing Software -->


<!-- ## Search Task Template {#sec-method-search-task-template} -->



## Procedure {#sec-method-procedure}

<!----------- fig:study-proc ----------->

```{r study-proc, fig.scap='(ref:scap-study-proc)', fig.cap = '(ref:cap-study-proc)',  echo=FALSE, out.width='100%', fig.align='center'}
nbShowFig("figs/study-proc")
```
<!-- each text reference needs to be their own line / paragraph ! -->
(ref:cap-study-proc) Longitudinal study procedure.

(ref:scap-study-proc) Longitudinal study procedure.

<!----------- fig:study-proc (leave a blank line before this) ----------->

The longitudinal study consisted of six data collection components, as illustrated in Figure \@ref(fig:study-proc).
They comprise three asynchronous **questionnaires** (`QSNR1`, `QSNR2`, `QSNR3`),
two **remote synchronous study phases** over Zoom video conferencing software (`PHASE1`, `PHASE3`),
and a set of four asynchronous **longitudinal tracking phases** (`PHASE2a`, `PHASE2b`, `PHASE2c`, `PHASE2d`).
These phases are discussed in detail in the following sections.
<!-- Reference it like Figure \@ref(fig:study-proc) -->


### `QSNR0`: Recruitment Questionnaire (Appendix \@ref(app-qsnr0)) {#sec-method-qsnr0}

Participants were recruited for the study via the recruitment questionnaire (`QSNR0`). 
The questionnaire contained questions about demographic information of the participant pool. 
The description of the study and the link to the questionnaire was posted in the Canvas Learning Management System used for the I303 course.


### `QSNR1`: Entry Questionnaire {#sec-method-qsnr1}

After recruitment, participants completed the entry questionnaire (QSNR1).
The purpose of QSNR1 was to capture their individual-differences, or
moderating variables, at the beginning of the semester.
Details of the data captured in SUR1 are
described below, with references to sections in the Appendix, where the
full-text of the questionnaire can be found.


#### Consent Form (Appendix \@ref(app-qsnr-consent-form))

The first page of QSNR1 was online consent form for participating in the study. Participants
were able to proceed with the study once they provided informed consent.




<!-- 1. **Search and IT proficiency:** (Appendix \@ref(app-qsnr-search-it-proficiency))
   Captures previous search experience, and proficiency in navigating the web.
   Some items are
    adapted from the *Digital Health Literacy Instrument (DHLI)* by
    [@van2017development], and the *Search Self-Efficacy scale (SSE)* by
    [@brennan2016factor]. -->

<!-- 2. **Course Load and other engagements:** (Appendix \@ref(app-qsnr-course-load))
   To determine how busy the participant
    will be in the semester, and how much time they plan to allocate for
    the course with which the study is integrated. This will help to
    establish the learner's context. -->

<!-- 3. **Note-taking Strategies:** (Appendix \@ref(app-qsnr-note-taking))
    Captures styles and
    strategies used by participants to take notes. Adapted from
    *Listening and Note Taking Survey* by
    [@note-taking-survey-penn-state], and *Note Taking Strategies
    Inventory* by [@note-taking-strategies-umass]. -->


#### Motivation (Appendix \@ref(app-qsnr-imi))

Adapted from the *Intrinsic Motivation Inventory (IMI)* by
[@ryan1982control], which is a multidimensional measurement device
intended to assess participants' subjective experience related to a
target activity (the assignments for the course they are taking).
The instrument assesses participants' interest/enjoyment, perceived
competence, effort/importance, pressure/tension, perceived choice,
and value/usefulness, while performing a given activity, thus
yielding six subscale scores. 
<!-- Three items in the value/usefulness
subscale were completed with contextual information when the
study site is finalized.  -->
The pressure/tension and the perceived
choice components were not included in the entry questionnaire QSNR1, and were
present in the mid-term (QSNR2) and exit (QSNR3) questionnaires.


#### Self-regulation (Appendix \@ref(app-qsnr-srq))

Adapted from the *Self-Regulation Questionnaire (SRQ)* by
[@brown1999self], which assess seven self-regulatory processes
through self-report: receiving relevant information, evaluating the
information and comparing it to norms, triggering change, searching
for options, formulating a plan, implementing the plan, and
assessing the plan's effectiveness (Section \@ref(sec-bg-learn-self-regulation)).



#### Metacognition (Appendix \@ref(app-qsnr-mai))

Adapted from the *Metacognivite Awareness Inventory (MAI)*,
originally proposed by [@schraw1994assessing] as a 52-item true /
false questionnaire, and later revised by [@terlecki2018call] to use
five-point Likert scales. The instrument measures two components of
cognition through self-report: knowledge about cognition, and
regulation of cognition (Section \@ref(sec-bg-learn-metacognition)).

After completing QSNR1 offline, participants were instructed to prepare
for the initial synchronous phase, `PHASE1`, by
installing Firefox web browser and the YASBIL extension on their machines.
<!-- *(ii)* get a quick introduction to concept maps (by watching a short video),
*(ii)* familiarizing themselves with the *Sero!* learning platform
(for creating and assessing concept maps).  -->
This was a one-time step.
If a
participant could not find the time for this step, they were informed
that an extra 5-10 minutes would be taken in the beginning of `PHASE1` to
complete this step.

The entry questionnaire and the software installation took about
10-15 minutes to complete. Participants were compensated with USD 5
for their time for completing this step. The questionnaire was published to the I-303 course students in
the first week of the Spring 2022 semester.
<!-- , and was closed after 18 participants participants have been recruited. -->



### `PHASE1`: Initial Phase {#sec-method-phase1}

The `PHASE1` of the data collection took place in the beginning of the semester.
The data-collection took place over a Zoom video call combined with YASBIL browsing logger installed in the participants' machines.
Participants were asked to share their screen for the whole duration of the phase.
Their screens and audio were recorded for the entire duration.
They had the freedom to turn off their video.
The total time for `PHASE1` was expected to not exceed 1.5 hours (90 minutes).
Participants were compensated with USD 25 for this phase.
The different components of `PHASE1` are described below.

#### Training Search Task

Participants performed a training search task to familiarize themselves with how to operate the YASBIL browser extension to log their browsing activity. The training task took around 2-5 minutes.


#### `PHASE1-FINANCE` and `PHASE1-UBUNTU`: Two Actual Search Tasks

<!----------- fig:search-task-repeated ----------->
```{r search-task-repeated, fig.scap='(ref:scap-search-task-repeated)', fig.cap = '(ref:cap-search-task-repeated)',  echo=FALSE, out.width='100%', fig.align='center'}
nbShowFig("figs/search-task-repeated")
```
<!-- each text reference needs to be their own single paragraph ! -->
(ref:cap-search-task-repeated) Prompts for the search task that was repeated in the final phase, on the topic of financial literacy.

(ref:scap-search-task-repeated) Prompts for repeated search task.

<!---- fig:search-task-repeated (leave a blank line before this) ------>

Participants performed two search tasks: `PHASE1-FINANCE`, and `PHASE1-UBUNTU`. 
The `PHASE1-FINANCE` task was repeated at the end of the semester as `PHASE3-FINANCE` task.
The `PHASE1-UBUNTU` task was not repeated, and instead the `PHASE3-BIAS` task tooK its place.
This helps to answer the research question RQ2 (Chapter \@ref(ch-rq)).
The order of the two search tasks were randomized.



The repeated search task `FINANCE` was on the topic of financial literacy, a topic that we posit can be considered as universally important to college students, and part of lifelong learning. 
The prompts for the `PHASE1-FINANCE` and `PHASE3-FINANCE` tasks are presented in Figure \@ref(fig:search-task-repeated).
The non-repeated search tasks were on topics that were taught in the I303 course: 
Ubuntu ethics (for `PHASE1`)
and
Algorithmic Bias (for `PHASE3`).
The prompts for these tasks are present in Figure \@ref(fig:search-task-new).

<!----------- fig:search-task-new ----------->
```{r search-task-new, fig.scap='(ref:scap-search-task-new)', fig.cap = '(ref:cap-search-task-new)',  echo=FALSE, out.width='100%', fig.align='center'}
nbShowFig("figs/search-task-new")
```
<!-- each text reference needs to be their own single paragraph ! -->
(ref:cap-search-task-new) Prompts for the non-repeating search tasks. Topics were selected from the I-303 course content.

(ref:scap-search-task-new) Prompts for non-repeated search task.

<!---- fig:search-task-new (leave a blank line before this) ------>

<!-- Each search task is expected to take around 20 minutes. -->

<!-- 

To answer RQ3 (effect of externalization and articulation in learning), each participant performed one of the search tasks while thinking aloud (Concurrent-Think Aloud or *CTA condition*), and performed the other search task in silence (*silent condition*). 
The choice of the search task for each of the conditions was randomized and balanced.

-->



Each search task began with a pre-task questionnaire (Appendix \@ref(app-phase13-pretask)), which asked participants to self-rate their pre-search knowledge-level and interest on the topic. 
Then participants turned on the YASBIL browsing logger and started searching. 
The deliverable for each search task was a written summary (artefact). 
After participants are satisfied with the quality of the deliverable, they turned off YASBIL browsing logger, and proceeded to the post-task questionnaire.

The post-task questionnaire (Appendix \@ref(app-phase13-posttask)) asked participants to self-rate their perceived learning and search outcomes, search experience, interest and motivation, and overall perceptions.
The pre-task and post-task questionnaires are adapted from [@collins2016assessing; @crescenzi2020adaptation]. 


<!-- 


After the two search tasks were completed, participants answered questions about whether they preferred the think-aloud condition or the silent condition, and why (Appendix \@ref(app-phase13-cta-v-silent)).


#### `PHASE1-SHEG`: Website Reliability Assessment

To assess participants' (mis)information evaluation capabilities, participants performed a website reliability assessment created by the @sheg2021website-reliability.

> *This task presents students with the website of the American College of Pediatricians (ACPeds.org) and asks them whether it is a trustworthy source to learn about children’s health. Despite the site’s professional title and appearance, the American College of Pediatricians is not the nation’s major professional organization of pediatricians. That designation belongs to the similarly named American Academy of Pediatrics.*
>
> *This exercise is an open web search in which students are free to stay on the American College of Pediatricians site or leave it to search for information about the group. Successful students will look beyond the surface features of the site and detect its agenda from its new releases or other focus issues. A faster route, however, is to leave the site almost immediately to search for reliable information about the true agenda of this organization.*
> 
> `r nbQuoteAuthor('--- @sheg2021website-reliability')`

The prompt for the `PHASE1-SHEG` task is present in Appendix \@ref(app-phase1-sheg)).


-->




#### Memory Span Test

`PHASE1` concluded with the assessment of the participant's working memory capacity (WMC) using a memory span task [@francis2004coglab].
Memory span assessment was kept in the synchronous phase because it is a timed task, and needs to conducted in a controlled (experimenter observed) condition.
The task has 25 trials. On each trial participants saw a list of items presented one at a time in random order and were asked to recall the items in the same order in which they were presented. If they got a list correct, the list length increased by 1 for that type of material. If they got a list incorrect, the list length decreased by 1.

The type of material participants were asked to recall were: digits, letters that sound dissimilar, letters that sound similar, short words, and long words. The outcome score was the list length of the last list that participants could correctly recall.



### `PHASE2A` - `PHASE2D`: Longitudinal Tracking Phase {#sec-method-phase2}

<!----------- fig:final-project-description ----------->

```{r final-project-description, fig.scap='(ref:scap-final-project-description)', fig.cap = '(ref:cap-final-project-description)',  echo=FALSE, out.width='100%', fig.align='center'}
nbShowFig("figs/final-project-description")
```
<!-- each text reference needs to be their own line / paragraph ! -->
(ref:cap-final-project-description) Final project description, setting up the longitudinal tracking phase of the study throughout the duration of the Spring 2022 semester. Text taken from I-303 course syllabus [@fleischmann2022i303]; emphasis and annotations our own.

(ref:scap-final-project-description) Final project description.

<!----------- fig:final-project-description (leave a blank line before this) ----------->

The four-part longitudinal tracking phases `PHASE2A` - `PHASE2D` were conducted asynchronously over the duration of the semester, to understand the change (or lack thereof) of participants' search behaviour and knowledge gain over time. 
Whenever participants worked on different parts of their final project (Ethical dilemma research paper for the I-303 course), as described in Figure \@ref(fig:final-project-description), they used Firefox web browser, and logged their browsing activity using YASBIL browsing logger. 
To protect their privacy, participants were regularly instructed to turn YASBIL on only when they were searching for information related to coursework. 
After each checkpoint assignment, participants self-uploaded an anonymized version of the working-draft of their research paper, and answered a post-task questionnaire.
The post-task questionnaire were similar to those used in the `PHASE1` and `PHASE3` search tasks, where participants self-reported, among other things, their perceived learning outcome and perceived search outcome [@collins2016assessing].
Participants received reminder emails before the deadline of each assignment, to remind them to use Firefox, turn YASBIL on, and upload the anonymized working-draft. 
To prevent participant drop-off, a staggered payment model was adopted during PHASE2.
Participants received USD 5 each when they completed `PHASE2A` and `PHASE2B`, USD 10 for `PHASE2C`, and USD 15 for `PHASE2D`, for a total of USD 35 for entire `PHASE2`. 
<!-- per each assignment for which they log data, up to a maximum of USD 20 for four assignments. -->








### `QSNR2`: Mid-Term Questionnaire {#sec-method-qsnr2}

The mid-term questionnaire `QSNR2` took place around the mid-point of the semester (Week 8-9). 
The purpose was to track whether any of the participants' individual difference measures (motivation, metacognition, and self-regulation) changed during the first half of the semester. 
This questionnaire was essentially a replica of the Entry Questionnaire `QSNR1`, with two modifications. First, the consent form and the demographics sections were absent. 
Second, the Intrinsic Motivation Inventory (IMI) included the 'pressure/tension' and the 'perceived choice' subscales, as these scales are more meaningful after an activity has taken place [@ryan1982control]. 
The IMI was also be reworded to reflect the mid-point of the semester.
Participants were compensated with USD 10 for completing this step.




### `PHASE3`: Final Phase {#sec-method-phase3}

The Final Phase `PHASE3` was similar in structure to the Initial Phase (`PHASE1`), and took place at the end of the semester, after all the course related tasks were completed by the participant. The purpose of the session is to record the 'evolved' search behaviour, and final knowledge state. 
Participants performed two search tasks: `PHASE3-FINANCE` and `PHASE3-BIAS`.
<!-- , and one website comparison task: `PHASE3-SHEG`. -->
<!-- In the end, there will be a short semi-structured interview. -->


#### `PHASE3-FINANCE` and `PHASE3-BIAS`: Two Actual Search Tasks


Of the two search tasks, the topic of one was repeated from `PHASE1` (financial literacy, Figure \@ref(fig:search-task-repeated)), while the topic of the other came from the course material: algorithmic bias (Figure \@ref(fig:search-task-new)). 
In both search tasks, participants were given the option of ***not searching*** if they felt confident enough to answer the search task questions from their prior knowledge [@crescenzi2020adaptation]. 
The deliverables for each search-task, as before, was a written summary (artefact).


<!-- 


#### `PHASE3-SHEG`: Website Comparison Assessment

Following the two search tasks, participants performed another website comparison assessment from the @sheg2021webpage-comparison. This task assessed their evolved information evaluation skills. 

To assess participants' (mis)information evaluation capabilities, they performed a Website Comparison assessment created by the @sheg2021webpage-comparison.

> *This task instructed participants to compare two websites and select the one that they would use to begin research on a topic. One of the pages is a Wikipedia article. The other has ".edu" in its URL, but the page reveals that the content is a student-written blog post created as part of a university course. Many students have been taught that Wikipedia pages are unreliable and should be avoided. Many have also been taught that sites with a .edu domain are trustworthy. This assessment gauges their ability to think in more nuanced ways about these kinds of websites.*
> 
> `r nbQuoteAuthor('--- @sheg2021webpage-comparison')`

The prompt for the `PHASE3-SHEG` task is present in Appendix \@ref(app-phase3-sheg)).

 -->


<!-- A semi-structured interview will be conducted in the end, where participants will reflect on their overall searching and learning experience. Certain 'interesting' handpicked sessions from their submitted logs may be identified and questions about them can also be asked to participants. A list of the interview questions asked in the Pilot Study (Appendix [\[ch-pilot-study\]](#ch-pilot-study){reference-type="ref" reference="ch-pilot-study"}) are presented in Appendix [\[app-post-task-interview\]](#app-post-task-interview){reference-type="ref" reference="app-post-task-interview"}, which can be reused. -->

Similar to `PHASE1`, participants were asked to share their screen for the whole duration of the phase. 
<!-- except for the interview, whence they can stop screen-sharing.  -->
Their screen and audio was recorded for the same. They had the freedom to turn off their video. The total time for `PHASE3` was expected to not exceed 1.5 hours (90 minutes). 
Participants were compensated with USD 30 for `PHASE3`. 
At the end of `PHASE3`, participants were instructed to complete the Exit Questionnaire `QSNR3` as soon as convenient.





### `QSNR3`: Exit Questionnaire {#sec-method-qsnr3}

The exit questionnaire `QSNR3` took place after the Final Phase `PHASE3`. 
The purpose was to record the final state of the participants' individual difference measures (motivation, metacognition, self-regulation), and whether these characteristics changed during the second half of the semester. 
As before, `QSNR3` questionnaire was essentially be a replica of `QSNR2`, with the Intrinsic Motivation Inventory (IMI) reworded to reflect the end-point of the semester 
<!-- (Appendix [\[app-final-survey\]](#app-final-survey){reference-type="ref" reference="app-final-survey"}).  -->
Participants were be compensated with USD 15 for their time for completing this step. 


After `QSNR3` was complete, participants received a bonus compensation of USD 30, if they completed all the phases of the LongSAL study without missing anything.



## Measures to Address Ethical Concerns

- Participation in the study (which was voluntary and compensated separately) and participation in the I303 course (which was required for graduation from the Informatics major) were sufficiently disentangled. The course instructors were never aware of which students participate in the course, and did not share any student data with the researchers. This avoided any undue pressure or expectation on the students.

- Participants logged their browsing activity using a Firefox browser extension YASBIL, which was been developed by the authors. The extension has an ON-OFF button, which put the participants in full control of when they wished to start and stop the logging. Participants had been sufficiently trained to use the browser extension, and were repeatedly reminded to log data only when they were working on the research paper assignments for the course, and not at other times.

- This study has been approved by The University of Texas at Austin Institutional Review Board (Submission ID: STUDY00002136, Date Approved: December 8, 2021).


After data collection for all the phases was complete, data analysis was performed on the collected data, which is discussed in the next chapter. 


<!-- 

## Measurement and Variables

### Independent / Explanatory: Search Interaction and Process Measures

The independent variables will be the search process behavioural
measures. Information searching behaviour will be operationalized using
a battery of search process measures, based on the three-stages of user
interaction discussed in Section
[\[sec-bg-search-3\-stage\]](#sec-bg-search-3-stage){reference-type="ref"
reference="sec-bg-search-3-stage"}. These measures include query
reformulation types and measures
(Table [\[tab-res-Q\-QRT-txnmy\]](#tab-res-Q-QRT-txnmy){reference-type="ref"
reference="tab-res-Q-QRT-txnmy"}), SERP examination measures, content
page examination measures, and overall search session measures (Table
[\[tab-search-behaviours\]](#tab-search-behaviours){reference-type="ref"
reference="tab-search-behaviours"}). A non-exhaustive list of such
search process measures which have been used in prior literature is
presented in Appendices
[\[sec-app-vars-qry\]](#sec-app-vars-qry){reference-type="ref"
reference="sec-app-vars-qry"} through
[\[sec-app-vars-overall-search\]](#sec-app-vars-overall-search){reference-type="ref"
reference="sec-app-vars-overall-search"}.

### Dependant / Outcome: Learning Measures

Learning (knowledge gain) will constitute the dependant variables, or
factor variables, when dichotomized via median split. Learning outcomes
are planned to be assessed by: *(i)* analysis of concept maps
[@halttunen2005assessing] (Appendix
[\[sec-app-vars-concept-maps\]](#sec-app-vars-concept-maps){reference-type="ref"
reference="sec-app-vars-concept-maps"}); *(ii)* analysis of written
summaries / knowledge artefacts [@wilson2013comparison]; and *(iii)*
instructor awarded scores and grades received by students in the course,
which will be obtained via FERPA release. Time, resources and
feasibility permitting, other possible ways of assessing learning can be
by using *(iv)* Online Research and Comprehension Assessment (ORCA)
[@leu2015new Table 3], [@kanniainen2021assessing Appendix A]; and *(v)*
information-use from websites in written artefacts
[@vakkari2019modeling; @vakkari2020usefulness].

### Moderator: Individual Differences

The variables of individual differences that are hypothesized to
moderate learning are *(i)* motivation, scored using Intrinsic
Motivation Inventory (IMI) [@ryan1982control]; *(ii)* self-regulation,
scored using Self-Regulation Questionnaire (SRQ) [@brown1999self];
*(iii)* metacognition, scored using revised Metacognivite Awareness
Inventory (MAI) [@schraw1994assessing; @terlecki2018call] *(iv)* memory
span, scored using memory span test [@francis2004coglab]; *(v)* search
proficiency, scored using Digital Health Literacy Instrument (DHLI)
[@van2017development] and Search Self-Efficacy Scale (SSE)
[@brennan2016factor]; *(vi)* information evaluation capabilities
(mastery / emerging / beginner), scored according to rubrics provided by
[@sheg2021webpage-comparison] assessments (an example grading rubric is
present in Appendix
[\[sec-app-pilot-ses3\]](#sec-app-pilot-ses3){reference-type="ref"
reference="sec-app-pilot-ses3"} Task 3).

## Data Analysis Plans

Exploratory data analysis (such as time series plotting) and descriptive
statistics will be used to identify if changes in search process /
interaction measures can be visually observed over the course of time.
Inferential statistics (difference between groups) will be employed to
test if there are significant differences in the learning measures
between student groups who learn more versus learn less. Pattern Mining
and clustering approaches may also be used to identify clusters or
patterns in the search process (time-series) data, and see if these
clusters correlate with high and low learning. An example of measuring
such changes in variables can be found in [@133 Section 3.2]. Advanced
search interactions such as parallel browsing behaviour (multi-tabbed
and multi-windowed browsing) may also be analysed
[@huang2010parallel; @labaj2012modeling].

## Anticipated Limitations

There are foreseeable limitations to this proposed longitudinal study.
First, there may not be enough participants who sign up for the study.
The remedy for this is choosing a course with a large number of
students, and using appealing messaging in the recruitment material
(e.g., an attractive video message was used to recruit participants in
the Pilot Study[^2]). Second, participants may drop off due to various
reasons during the study. This can be tackled by regularly communicating
with the participants, keeping them engaged with affectionate, caring
and encouraging messaging, and letting them know that their
participation is valued highly by the researchers. Third, participants
may not show any changes in their search behaviours, of the changes may
be random. As one anonymous reviewer put it "the smart kids will show up
smart and with good search skills and they will leave smart with good
search skills and they will not change their inherent behavior over the
time. Similarly, the dumb kids will show up dumb, do whatever keeps them
dumb and end up dumb." Alternatively, there may be are not changes over
time, but rather strategies that are consistently followed by students
who will learn more, and students who will learn less. There is no easy
fix to this, and if this happens, it will be treated as a finding from
the study. A possible rescue from this situation would then be to use
the (semi) qualitative data -- the semi structured interview at the end,
the concurrent think alouds, and others -- to derive interesting
findings.


-->
